{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "76a33dbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfd0c01c",
   "metadata": {},
   "source": [
    "# init the perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7b1e6f54",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# create a new class for a perceptron with a hidden layer\n",
    "\n",
    "\n",
    "class Perceptron:\n",
    "    rng = np.random.default_rng()\n",
    "    errArr = []\n",
    "\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        self.hiddenWeights = np.random.normal(0, 1/2, (hidden_size, input_size))\n",
    "        self.hiddenThreshold = np.zeros([hidden_size,1])\n",
    "        self.outputWeights = np.random.normal(0, 1/hidden_size, (hidden_size))\n",
    "        self.outputThreshold = np.zeros(output_size)\n",
    "\n",
    "        if(0):\n",
    "            #shapes of the initializations\n",
    "            print(\"hiddenWeights.shape: \", self.hiddenWeights.shape)\n",
    "            print(\"hiddenThreshold.shape: \", self.hiddenThreshold.shape)\n",
    "            print(\"outputWeights.shape: \", self.outputWeights.shape)\n",
    "            print(\"outputThreshold.shape: \", self.outputThreshold.shape)\n",
    "\n",
    "            # print the values\n",
    "            print(\"hiddenWeights: \", self.hiddenWeights)\n",
    "            print(\"hiddenThreshold: \", self.hiddenThreshold)\n",
    "            print(\"outputWeights: \", self.outputWeights)\n",
    "            print(\"outputThreshold: \", self.outputThreshold)\n",
    "            \n",
    "\n",
    "    def tanh(self, x):\n",
    "        return np.tanh(x)\n",
    "    \n",
    "    def tanhDerivative(self, x):\n",
    "        return 1 - np.power(np.tanh(x), 2)\n",
    "\n",
    "    def forward(self, input):\n",
    "        self.hidden_b = np.dot(self.hiddenWeights, input.T) - self.hiddenThreshold\n",
    "        self.hiddenLayer = self.tanh(self.hidden_b)\n",
    "        self.output_B = np.dot(self.outputWeights.T, self.hiddenLayer) - self.outputThreshold\n",
    "        self.outputLayer = self.tanh(self.output_B)\n",
    "        return self.outputLayer\n",
    "    \n",
    "    def backward(self, X, target, eta, output):      \n",
    "        error = target - output                                                           #(batch_size,)\n",
    "       \n",
    "        error_2 = error * self.tanhDerivative(self.output_B)                                   #(batch_size,)\n",
    "      \n",
    "        error_2_reshaped = error_2[:, np.newaxis]\n",
    "        output_weights_reshaped = self.outputWeights[np.newaxis, :]\n",
    "        tmp = error_2_reshaped * output_weights_reshaped\n",
    "        gprime = self.tanhDerivative(self.hidden_b)\n",
    "        error_1 = (tmp * gprime.T)\n",
    "\n",
    "        self.outputWeights += error_2 @ self.hiddenLayer.T *eta\n",
    "        self.outputThreshold -= eta * np.sum(error_2, axis=0, keepdims=True)\n",
    "\n",
    "        self.hiddenWeights += error_1.T @ X * eta\n",
    "        self.hiddenThreshold -= eta * np.sum(error_1, axis=0, keepdims=True).T\n",
    "\n",
    "\n",
    "    def classificationError(self, input, target):\n",
    "        prediction = np.sign(self.forward(input))\n",
    "        return 0.5 * np.mean(np.abs(prediction-target))\n",
    "\n",
    "    def trainMiniBatches(self, xTrain, yTrain, eta, epochs, mB):\n",
    "        \n",
    "        for _ in range(epochs):\n",
    "            mu = self.rng.choice(xTrain.shape[0],size=mB, replace=True)\n",
    "            xTrain_rand = xTrain[mu]\n",
    "            yTrain_rand = yTrain[mu]\n",
    "\n",
    "            output = self.forward(xTrain_rand)\n",
    "            self.backward(xTrain_rand, yTrain_rand, eta=eta)\n",
    "        return    \n",
    "\n",
    "    def trainMiniBatchesWhile(self, xTrain, yTrain, xValid, yValid, eta, epochs, mB):\n",
    "        i = 0\n",
    "        err = 1\n",
    "        lowestErr = 1\n",
    "\n",
    "        while err > 0.115:\n",
    "\n",
    "            if i > 1000:\n",
    "                eta = 0.001\n",
    "            \n",
    "\n",
    "            oldErr = err\n",
    "            mu = self.rng.choice(xTrain.shape[0],size=mB, replace=False)\n",
    "            xTrain_rand = xTrain[mu]\n",
    "            yTrain_rand = yTrain[mu]\n",
    "\n",
    "            output = self.forward(xTrain_rand,)\n",
    "            self.backward(xTrain_rand, yTrain_rand, eta=eta, output=output)\n",
    "\n",
    "            # calculate the error\n",
    "            err = self.classificationError(xValid, yValid)\n",
    "            self.errArr.append(err)\n",
    "\n",
    "            if err<lowestErr:\n",
    "                lowestErr = err\n",
    "            \n",
    "            if (i % 400 == 0):\n",
    "                print(\"epoch: \", i, \"error: \", err, \"lowestErr: \", lowestErr)\n",
    "            \n",
    "            i += 1\n",
    "\n",
    "            # if new lowest error, and error < 0.13 save the weights and thresholds\n",
    "            if (err < 0.12):\n",
    "                np.savetxt(\"csv/w1.csv\", self.hiddenWeights, delimiter=\",\")\n",
    "                np.savetxt(\"csv/w2.csv\", self.outputWeights, delimiter=\",\")\n",
    "                np.savetxt(\"csv/t1.csv\", self.hiddenThreshold, delimiter=\",\")\n",
    "                np.savetxt(\"csv/t2.csv\", self.outputThreshold, delimiter=\",\")\n",
    "         \n",
    "            \n",
    "        print(\"epoch: \", i, \"error: \", err, \"lowestErr: \", lowestErr)\n",
    "        \"\"\"print(\"hidden Weights: \", self.hiddenWeights)\n",
    "        print(\"hidden Threshold: \", self.hiddenThreshold)\n",
    "        print(\"output Weights: \", self.outputWeights)\n",
    "        print(\"output Threshold: \", self.outputThreshold)\"\"\"\n",
    "\n",
    "\n",
    "        return  \n",
    "            \n",
    "\n",
    "\n",
    "\n",
    "perceptron = Perceptron(2, 2, 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4aa2f82d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    # read the training and validation data\n",
    "    training_set = np.loadtxt('training_set.csv', delimiter=',')\n",
    "    validation_set = np.loadtxt('validation_set.csv', delimiter=',')\n",
    "\n",
    "    xTraining = training_set[:, :2]\n",
    "    yTraining = training_set[:, 2]\n",
    "\n",
    "    xValidation = validation_set[:, :2]\n",
    "    yValidation = validation_set[:, 2]\n",
    "\n",
    "    xTraining_mean = xTraining.mean(axis=0)\n",
    "    xTraining_std = xTraining.std(axis=0)\n",
    "\n",
    "    xTraining_normalised = (xTraining-xTraining_mean)/xTraining_std\n",
    "    xValidation_normalised = (xValidation-xTraining_mean)/xTraining_std\n",
    "\n",
    "    perceptron = Perceptron(input_size=2, hidden_size=15, output_size=1)\n",
    "\n",
    "    # train the perceptron\n",
    "    #perceptron.trainMiniBatches(xTraining_normalised, yTraining, eta=0.001, epochs=100000, mB=2**8)\n",
    "\n",
    "    perceptron.trainMiniBatchesWhile(xTraining_normalised, yTraining, xValidation_normalised, yValidation, eta=0.01, epochs=1000, mB=2**9)\n",
    "\n",
    "    # classify the validation data\n",
    "    valErr = perceptron.classificationError(xValidation_normalised, yValidation)\n",
    "    print(\"Validation error: \", valErr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "efe3ab69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:  0 error:  0.1516 lowestErr:  0.1516\n",
      "epoch:  400 error:  0.141 lowestErr:  0.1372\n",
      "epoch:  800 error:  0.138 lowestErr:  0.1348\n",
      "epoch:  1200 error:  0.138 lowestErr:  0.134\n",
      "epoch:  1600 error:  0.1392 lowestErr:  0.134\n",
      "epoch:  2000 error:  0.1422 lowestErr:  0.134\n",
      "epoch:  2400 error:  0.1376 lowestErr:  0.134\n",
      "epoch:  2800 error:  0.1352 lowestErr:  0.134\n",
      "epoch:  3200 error:  0.139 lowestErr:  0.1338\n",
      "epoch:  3600 error:  0.1352 lowestErr:  0.1318\n",
      "epoch:  4000 error:  0.1322 lowestErr:  0.1304\n",
      "epoch:  4400 error:  0.1388 lowestErr:  0.1294\n",
      "epoch:  4800 error:  0.1304 lowestErr:  0.1286\n",
      "epoch:  5200 error:  0.1296 lowestErr:  0.128\n",
      "epoch:  5600 error:  0.1294 lowestErr:  0.1272\n",
      "epoch:  6000 error:  0.1276 lowestErr:  0.127\n",
      "epoch:  6400 error:  0.128 lowestErr:  0.1264\n",
      "epoch:  6800 error:  0.1272 lowestErr:  0.126\n",
      "epoch:  7200 error:  0.128 lowestErr:  0.1258\n",
      "epoch:  7600 error:  0.1274 lowestErr:  0.1254\n",
      "epoch:  8000 error:  0.1266 lowestErr:  0.1252\n",
      "epoch:  8400 error:  0.1282 lowestErr:  0.125\n",
      "epoch:  8800 error:  0.1268 lowestErr:  0.125\n",
      "epoch:  9200 error:  0.1276 lowestErr:  0.1248\n",
      "epoch:  9600 error:  0.125 lowestErr:  0.1248\n",
      "epoch:  10000 error:  0.1254 lowestErr:  0.1248\n",
      "epoch:  10400 error:  0.1258 lowestErr:  0.1244\n",
      "epoch:  10800 error:  0.1258 lowestErr:  0.1242\n",
      "epoch:  11200 error:  0.126 lowestErr:  0.1242\n",
      "epoch:  11600 error:  0.1268 lowestErr:  0.124\n",
      "epoch:  12000 error:  0.1252 lowestErr:  0.1236\n",
      "epoch:  12400 error:  0.1256 lowestErr:  0.1234\n",
      "epoch:  12800 error:  0.1252 lowestErr:  0.1234\n",
      "epoch:  13200 error:  0.1254 lowestErr:  0.1234\n",
      "epoch:  13600 error:  0.1242 lowestErr:  0.1234\n",
      "epoch:  14000 error:  0.1252 lowestErr:  0.1234\n",
      "epoch:  14400 error:  0.1252 lowestErr:  0.1234\n",
      "epoch:  14800 error:  0.124 lowestErr:  0.1232\n",
      "epoch:  15200 error:  0.1238 lowestErr:  0.123\n",
      "epoch:  15600 error:  0.124 lowestErr:  0.123\n",
      "epoch:  16000 error:  0.1244 lowestErr:  0.123\n",
      "epoch:  16400 error:  0.1242 lowestErr:  0.123\n",
      "epoch:  16800 error:  0.1244 lowestErr:  0.123\n",
      "epoch:  17200 error:  0.1242 lowestErr:  0.123\n",
      "epoch:  17600 error:  0.1244 lowestErr:  0.123\n",
      "epoch:  18000 error:  0.1246 lowestErr:  0.123\n",
      "epoch:  18400 error:  0.1238 lowestErr:  0.123\n",
      "epoch:  18800 error:  0.1242 lowestErr:  0.123\n",
      "epoch:  19200 error:  0.1244 lowestErr:  0.1228\n",
      "epoch:  19600 error:  0.1242 lowestErr:  0.1228\n",
      "epoch:  20000 error:  0.1238 lowestErr:  0.1228\n",
      "epoch:  20400 error:  0.1242 lowestErr:  0.1228\n",
      "epoch:  20800 error:  0.124 lowestErr:  0.1224\n",
      "epoch:  21200 error:  0.1244 lowestErr:  0.1224\n",
      "epoch:  21600 error:  0.124 lowestErr:  0.1224\n",
      "epoch:  22000 error:  0.1236 lowestErr:  0.1224\n",
      "epoch:  22400 error:  0.124 lowestErr:  0.1224\n",
      "epoch:  22800 error:  0.1242 lowestErr:  0.1224\n",
      "epoch:  23200 error:  0.1248 lowestErr:  0.1222\n",
      "epoch:  23600 error:  0.124 lowestErr:  0.1222\n",
      "epoch:  24000 error:  0.125 lowestErr:  0.122\n",
      "epoch:  24400 error:  0.1234 lowestErr:  0.122\n",
      "epoch:  24800 error:  0.1236 lowestErr:  0.122\n",
      "epoch:  25200 error:  0.1242 lowestErr:  0.122\n",
      "epoch:  25600 error:  0.1244 lowestErr:  0.1218\n",
      "epoch:  26000 error:  0.1232 lowestErr:  0.1218\n",
      "epoch:  26400 error:  0.1236 lowestErr:  0.1218\n",
      "epoch:  26800 error:  0.1238 lowestErr:  0.1218\n",
      "epoch:  27200 error:  0.1244 lowestErr:  0.1218\n",
      "epoch:  27600 error:  0.1236 lowestErr:  0.1218\n",
      "epoch:  28000 error:  0.1238 lowestErr:  0.1218\n",
      "epoch:  28400 error:  0.1238 lowestErr:  0.1218\n",
      "epoch:  28800 error:  0.1238 lowestErr:  0.1216\n",
      "epoch:  29200 error:  0.124 lowestErr:  0.1216\n",
      "epoch:  29600 error:  0.1246 lowestErr:  0.1216\n",
      "epoch:  30000 error:  0.1242 lowestErr:  0.1216\n",
      "epoch:  30400 error:  0.1222 lowestErr:  0.1216\n",
      "epoch:  30800 error:  0.1248 lowestErr:  0.1216\n",
      "epoch:  31200 error:  0.1246 lowestErr:  0.1216\n",
      "epoch:  31600 error:  0.1246 lowestErr:  0.1216\n",
      "epoch:  32000 error:  0.1238 lowestErr:  0.1216\n",
      "epoch:  32400 error:  0.1242 lowestErr:  0.1216\n",
      "epoch:  32800 error:  0.124 lowestErr:  0.1216\n",
      "epoch:  33200 error:  0.1232 lowestErr:  0.1216\n",
      "epoch:  33600 error:  0.123 lowestErr:  0.1212\n",
      "epoch:  34000 error:  0.1234 lowestErr:  0.1212\n",
      "epoch:  34400 error:  0.1246 lowestErr:  0.1212\n",
      "epoch:  34800 error:  0.124 lowestErr:  0.1212\n",
      "epoch:  35200 error:  0.125 lowestErr:  0.1212\n",
      "epoch:  35600 error:  0.1242 lowestErr:  0.1212\n",
      "epoch:  36000 error:  0.122 lowestErr:  0.1212\n",
      "epoch:  36400 error:  0.1226 lowestErr:  0.1212\n",
      "epoch:  36800 error:  0.1234 lowestErr:  0.1212\n",
      "epoch:  37200 error:  0.1222 lowestErr:  0.1212\n",
      "epoch:  37600 error:  0.123 lowestErr:  0.1212\n",
      "epoch:  38000 error:  0.1232 lowestErr:  0.1212\n",
      "epoch:  38400 error:  0.1236 lowestErr:  0.1212\n",
      "epoch:  38800 error:  0.1238 lowestErr:  0.1212\n",
      "epoch:  39200 error:  0.1234 lowestErr:  0.1212\n",
      "epoch:  39600 error:  0.1234 lowestErr:  0.1212\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
